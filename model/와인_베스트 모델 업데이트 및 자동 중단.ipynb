{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베스트 모델 만들기 - 와인 사례\n",
    "## 이진 분류\n",
    "## 베스트 모델 업데이트하기 - 자동 중단, 그래프로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "df_pre = pd.read_csv('dataset/wine.csv', header=None)\n",
    "df = df_pre.sample(frac=1)\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12]\n",
    "Y = dataset[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential([\n",
    "    Dense(30, input_dim=12, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"final{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer_callback = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37780, saving model to ./model/final001-0.3778.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37780 to 0.29494, saving model to ./model/final002-0.2949.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29494 to 0.27814, saving model to ./model/final003-0.2781.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27814 to 0.26247, saving model to ./model/final004-0.2625.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.26247 to 0.25282, saving model to ./model/final005-0.2528.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.25282 to 0.24013, saving model to ./model/final006-0.2401.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24013 to 0.23370, saving model to ./model/final007-0.2337.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23370 to 0.22727, saving model to ./model/final008-0.2273.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22727 to 0.21986, saving model to ./model/final009-0.2199.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21986 to 0.21408, saving model to ./model/final010-0.2141.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.21408 to 0.20426, saving model to ./model/final011-0.2043.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20426 to 0.19580, saving model to ./model/final012-0.1958.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.19580 to 0.19269, saving model to ./model/final013-0.1927.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.19269 to 0.18879, saving model to ./model/final014-0.1888.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.18879 to 0.18813, saving model to ./model/final015-0.1881.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.18813 to 0.18508, saving model to ./model/final016-0.1851.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.18508 to 0.18346, saving model to ./model/final017-0.1835.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18346\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.18346 to 0.18130, saving model to ./model/final019-0.1813.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.18130 to 0.18016, saving model to ./model/final020-0.1802.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.18016 to 0.17839, saving model to ./model/final021-0.1784.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.17839 to 0.17751, saving model to ./model/final022-0.1775.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.17751 to 0.17567, saving model to ./model/final023-0.1757.hdf5\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.17567\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.17567 to 0.17542, saving model to ./model/final025-0.1754.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17542 to 0.17243, saving model to ./model/final026-0.1724.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.17243 to 0.17115, saving model to ./model/final027-0.1711.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.17115\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17115 to 0.17106, saving model to ./model/final029-0.1711.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.17106 to 0.16888, saving model to ./model/final030-0.1689.hdf5\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.16888\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.16888 to 0.16570, saving model to ./model/final032-0.1657.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.16570 to 0.16483, saving model to ./model/final033-0.1648.hdf5\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16483\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16483 to 0.16176, saving model to ./model/final035-0.1618.hdf5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16176\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.16176 to 0.16102, saving model to ./model/final037-0.1610.hdf5\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16102 to 0.15814, saving model to ./model/final038-0.1581.hdf5\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.15814\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15814 to 0.15549, saving model to ./model/final040-0.1555.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15549 to 0.15394, saving model to ./model/final041-0.1539.hdf5\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.15394\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15394 to 0.15203, saving model to ./model/final043-0.1520.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.15203\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.15203 to 0.14849, saving model to ./model/final045-0.1485.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.14849 to 0.14687, saving model to ./model/final046-0.1469.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.14687 to 0.14383, saving model to ./model/final047-0.1438.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.14383\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.14383\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.14383 to 0.14321, saving model to ./model/final050-0.1432.hdf5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.14321\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.14321\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.14321 to 0.14146, saving model to ./model/final053-0.1415.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.14146 to 0.13681, saving model to ./model/final054-0.1368.hdf5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.13681\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.13681 to 0.13449, saving model to ./model/final056-0.1345.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.13449\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.13449\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.13449\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.13449\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.13449 to 0.13204, saving model to ./model/final061-0.1320.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.13204 to 0.13027, saving model to ./model/final062-0.1303.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.13027 to 0.12949, saving model to ./model/final063-0.1295.hdf5\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.12949 to 0.12668, saving model to ./model/final064-0.1267.hdf5\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.12668 to 0.12620, saving model to ./model/final065-0.1262.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.12620 to 0.12469, saving model to ./model/final066-0.1247.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.12469 to 0.12430, saving model to ./model/final067-0.1243.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.12430\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.12430 to 0.12218, saving model to ./model/final069-0.1222.hdf5\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.12218\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.12218\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.12218 to 0.11995, saving model to ./model/final072-0.1199.hdf5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.11995\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.11995\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.11995 to 0.11841, saving model to ./model/final075-0.1184.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.11841 to 0.11767, saving model to ./model/final076-0.1177.hdf5\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.11767\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.11767\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.11767\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.11767\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.11767 to 0.11718, saving model to ./model/final081-0.1172.hdf5\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.11718 to 0.11349, saving model to ./model/final082-0.1135.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.11349 to 0.11257, saving model to ./model/final083-0.1126.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.11257 to 0.11082, saving model to ./model/final084-0.1108.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.11082\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.11082 to 0.11058, saving model to ./model/final086-0.1106.hdf5\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.11058\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.11058\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.11058 to 0.10915, saving model to ./model/final089-0.1092.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.10915 to 0.10511, saving model to ./model/final092-0.1051.hdf5\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10511\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.10511 to 0.10467, saving model to ./model/final094-0.1047.hdf5\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10467\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.10467 to 0.10442, saving model to ./model/final096-0.1044.hdf5\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.10442 to 0.10303, saving model to ./model/final097-0.1030.hdf5\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.10303 to 0.10249, saving model to ./model/final098-0.1025.hdf5\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.10249 to 0.10206, saving model to ./model/final099-0.1021.hdf5\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10206\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.10206\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.10206 to 0.10036, saving model to ./model/final102-0.1004.hdf5\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.10036\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.10036 to 0.10000, saving model to ./model/final104-0.1000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00105: val_loss improved from 0.10000 to 0.09825, saving model to ./model/final105-0.0983.hdf5\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.09825\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.09825\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.09825\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.09825\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.09825 to 0.09748, saving model to ./model/final110-0.0975.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.09748 to 0.09667, saving model to ./model/final111-0.0967.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.09667 to 0.09379, saving model to ./model/final112-0.0938.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.09379 to 0.09367, saving model to ./model/final113-0.0937.hdf5\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.09367\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.09367 to 0.09276, saving model to ./model/final115-0.0928.hdf5\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.09276 to 0.09207, saving model to ./model/final116-0.0921.hdf5\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.09207\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.09207 to 0.09137, saving model to ./model/final118-0.0914.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.09137 to 0.09109, saving model to ./model/final119-0.0911.hdf5\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.09109\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.09109 to 0.09105, saving model to ./model/final121-0.0910.hdf5\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.09105 to 0.08886, saving model to ./model/final122-0.0889.hdf5\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.08886 to 0.08866, saving model to ./model/final123-0.0887.hdf5\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.08866\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.08866\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.08866\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.08866\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.08866\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.08866 to 0.08623, saving model to ./model/final129-0.0862.hdf5\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.08623 to 0.08590, saving model to ./model/final130-0.0859.hdf5\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.08590 to 0.08564, saving model to ./model/final131-0.0856.hdf5\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.08564\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.08564\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.08564\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.08564\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.08564 to 0.08395, saving model to ./model/final136-0.0839.hdf5\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.08395\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.08395 to 0.08316, saving model to ./model/final138-0.0832.hdf5\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.08316 to 0.08295, saving model to ./model/final139-0.0829.hdf5\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.08295 to 0.08270, saving model to ./model/final140-0.0827.hdf5\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.08270 to 0.08165, saving model to ./model/final141-0.0816.hdf5\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.08165 to 0.08107, saving model to ./model/final142-0.0811.hdf5\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.08107 to 0.08068, saving model to ./model/final143-0.0807.hdf5\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.08068\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.08068\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.08068 to 0.07950, saving model to ./model/final146-0.0795.hdf5\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.07950\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.07950 to 0.07927, saving model to ./model/final148-0.0793.hdf5\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.07927 to 0.07876, saving model to ./model/final149-0.0788.hdf5\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.07876 to 0.07871, saving model to ./model/final150-0.0787.hdf5\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.07871\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.07871\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.07871\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.07871 to 0.07843, saving model to ./model/final154-0.0784.hdf5\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.07843 to 0.07648, saving model to ./model/final155-0.0765.hdf5\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.07648\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.07648\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.07648\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.07648\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.07648 to 0.07578, saving model to ./model/final160-0.0758.hdf5\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.07578\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.07578\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.07578\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.07578\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.07578 to 0.07562, saving model to ./model/final165-0.0756.hdf5\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.07562 to 0.07404, saving model to ./model/final166-0.0740.hdf5\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.07404 to 0.07389, saving model to ./model/final167-0.0739.hdf5\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.07389 to 0.07293, saving model to ./model/final168-0.0729.hdf5\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.07293\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.07293 to 0.07197, saving model to ./model/final170-0.0720.hdf5\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.07197\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.07197\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.07197 to 0.07086, saving model to ./model/final173-0.0709.hdf5\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.07086 to 0.07058, saving model to ./model/final174-0.0706.hdf5\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.07058 to 0.06774, saving model to ./model/final185-0.0677.hdf5\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.06774 to 0.06732, saving model to ./model/final186-0.0673.hdf5\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.06732 to 0.06701, saving model to ./model/final187-0.0670.hdf5\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.06701\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.06701\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.06701 to 0.06673, saving model to ./model/final190-0.0667.hdf5\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.06673\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.06673 to 0.06628, saving model to ./model/final192-0.0663.hdf5\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.06628 to 0.06582, saving model to ./model/final193-0.0658.hdf5\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.06582\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06582\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.06582 to 0.06521, saving model to ./model/final196-0.0652.hdf5\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.06521\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.06521 to 0.06448, saving model to ./model/final198-0.0645.hdf5\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.06448 to 0.06432, saving model to ./model/final199-0.0643.hdf5\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.06432 to 0.06427, saving model to ./model/final200-0.0643.hdf5\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.06427\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.06427\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.06427\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.06427\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.06427\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.06427 to 0.06316, saving model to ./model/final206-0.0632.hdf5\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.06316\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.06316\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.06316 to 0.06291, saving model to ./model/final209-0.0629.hdf5\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.06291\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.06291 to 0.06225, saving model to ./model/final211-0.0622.hdf5\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.06225\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.06225\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.06225\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.06225\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.06225\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.06225 to 0.06170, saving model to ./model/final217-0.0617.hdf5\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.06170\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.06170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00220: val_loss did not improve from 0.06170\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.06170 to 0.06163, saving model to ./model/final221-0.0616.hdf5\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.06163\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.06163\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.06163\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.06163\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.06163\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.06163\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.06163 to 0.06149, saving model to ./model/final228-0.0615.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.06149 to 0.06028, saving model to ./model/final229-0.0603.hdf5\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.06028 to 0.06024, saving model to ./model/final230-0.0602.hdf5\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.06024\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.06024\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.06024 to 0.05997, saving model to ./model/final233-0.0600.hdf5\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.05997\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.05997\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.05997 to 0.05995, saving model to ./model/final236-0.0600.hdf5\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.05995\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.05995\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.05995 to 0.05924, saving model to ./model/final239-0.0592.hdf5\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.05924\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.05924 to 0.05914, saving model to ./model/final251-0.0591.hdf5\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.05914 to 0.05864, saving model to ./model/final252-0.0586.hdf5\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.05864\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.05864 to 0.05803, saving model to ./model/final254-0.0580.hdf5\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.05803 to 0.05788, saving model to ./model/final255-0.0579.hdf5\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.05788\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.05788\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.05788 to 0.05764, saving model to ./model/final258-0.0576.hdf5\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.05764\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.05764 to 0.05756, saving model to ./model/final267-0.0576.hdf5\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.05756\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.05756 to 0.05694, saving model to ./model/final285-0.0569.hdf5\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.05694\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.05694\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.05694 to 0.05672, saving model to ./model/final288-0.0567.hdf5\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.05672 to 0.05626, saving model to ./model/final289-0.0563.hdf5\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.05626\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.05626 to 0.05612, saving model to ./model/final302-0.0561.hdf5\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.05612\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.05612\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.05612\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.05612\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.05612\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.05612\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.05612 to 0.05591, saving model to ./model/final309-0.0559.hdf5\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.05591\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.05591\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.05591\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.05591 to 0.05543, saving model to ./model/final313-0.0554.hdf5\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.05543\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.05543\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.05543\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.05543 to 0.05468, saving model to ./model/final317-0.0547.hdf5\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.05468 to 0.05460, saving model to ./model/final337-0.0546.hdf5\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.05460\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.05460\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.05460\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.05460\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.05460\n",
      "\n",
      "Epoch 00343: val_loss improved from 0.05460 to 0.05452, saving model to ./model/final343-0.0545.hdf5\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.05452\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.05452 to 0.05447, saving model to ./model/final355-0.0545.hdf5\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.05447\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.05447 to 0.05422, saving model to ./model/final357-0.0542.hdf5\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.05422 to 0.05407, saving model to ./model/final358-0.0541.hdf5\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.05407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00362: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.05407\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.05407 to 0.05345, saving model to ./model/final374-0.0535.hdf5\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.05345\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.05345 to 0.05309, saving model to ./model/final389-0.0531.hdf5\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.05309\n",
      "\n",
      "Epoch 00437: val_loss improved from 0.05309 to 0.05270, saving model to ./model/final437-0.0527.hdf5\n",
      "\n",
      "Epoch 00438: val_loss improved from 0.05270 to 0.05218, saving model to ./model/final438-0.0522.hdf5\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.05218\n",
      "\n",
      "Epoch 00481: val_loss improved from 0.05218 to 0.05211, saving model to ./model/final481-0.0521.hdf5\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.05211\n",
      "\n",
      "Epoch 00519: val_loss improved from 0.05211 to 0.05147, saving model to ./model/final519-0.0515.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00520: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.05147\n",
      "\n",
      "Epoch 00602: val_loss improved from 0.05147 to 0.05140, saving model to ./model/final602-0.0514.hdf5\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.05140\n",
      "\n",
      "Epoch 00621: val_loss improved from 0.05140 to 0.05097, saving model to ./model/final621-0.0510.hdf5\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.05097\n",
      "\n",
      "Epoch 00671: val_loss improved from 0.05097 to 0.05071, saving model to ./model/final671-0.0507.hdf5\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.05071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00685: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.05071\n",
      "\n",
      "Epoch 00704: val_loss improved from 0.05071 to 0.05014, saving model to ./model/final704-0.0501.hdf5\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.05014\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.05014\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/1 - 0s - loss: 0.0241 - accuracy: 0.9891\n",
      "\n",
      " Accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = load_model('model/final704-0.0501.hdf5')\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
