{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자 레벨 기계번역기\n",
    "### 참조: [sequence-to-sequence 10분만에 이해하기](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
    "### 다운로드: [프랑스-영어 병렬 코퍼스](http://www.manythings.org/anki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 확인 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170651"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lines = pd.read_csv('data/fra.txt', names=['dst', 'desc'], sep='\\t')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What's the date today?</th>\n",
       "      <td>Le quantième sommes-nous ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>She disliked him.</th>\n",
       "      <td>Elle ne l'aimait pas.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Go play in traffic.</th>\n",
       "      <td>Va mourir.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is she gone?</th>\n",
       "      <td>S'en est-elle allée ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Your plan sounds great.</th>\n",
       "      <td>Ton plan semble excellent.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dst  \\\n",
       "What's the date today?   Le quantième sommes-nous ?   \n",
       "She disliked him.             Elle ne l'aimait pas.   \n",
       "Go play in traffic.                      Va mourir.   \n",
       "Is she gone?                  S'en est-elle allée ?   \n",
       "Your plan sounds great.  Ton plan semble excellent.   \n",
       "\n",
       "                                                                      desc  \n",
       "What's the date today?   CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "She disliked him.        CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "Go play in traffic.      CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "Is she gone?             CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "Your plan sounds great.  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60,000개의 샘플만 가지고 기계 번역기를 구축\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Go.</th>\n",
       "      <td>Va !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hi.</th>\n",
       "      <td>Salut !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hi.</th>\n",
       "      <td>Salut.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run!</th>\n",
       "      <td>Cours !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run!</th>\n",
       "      <td>Courez !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dst                                               desc\n",
       "Go.       Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "Hi.    Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "Hi.     Salut.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "Run!   Cours !  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "Run!  Courez !  CC-BY 2.0 (France) Attribution: tatoeba.org #9..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Go.         Va !\n",
       "Hi.      Salut !\n",
       "Hi.       Salut.\n",
       "Run!     Cours !\n",
       "Run!    Courez !\n",
       "Name: dst, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['dst'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Go.     CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "Hi.     CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "Hi.     CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "Run!    CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "Run!    CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "Name: desc, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['desc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc 컬럼 삭제\n",
    "del lines['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index       dst\n",
       "0   Go.      Va !\n",
       "1   Hi.   Salut !\n",
       "2   Hi.    Salut.\n",
       "3  Run!   Cours !\n",
       "4  Run!  Courez !"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 제거\n",
    "lines = lines.reset_index()\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src       dst\n",
       "0   Go.      Va !\n",
       "1   Hi.   Salut !\n",
       "2   Hi.    Salut.\n",
       "3  Run!   Cours !\n",
       "4  Run!  Courez !"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼명 변경\n",
    "lines.rename(columns = {'index' : 'src'}, inplace = True)\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Take mine.</td>\n",
       "      <td>Prenez le mien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8302</th>\n",
       "      <td>I'm so unlucky!</td>\n",
       "      <td>Quelle poisse j'ai !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31645</th>\n",
       "      <td>We're closing early.</td>\n",
       "      <td>Nous fermons tôt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52071</th>\n",
       "      <td>Have you read that book?</td>\n",
       "      <td>As-tu lu ce livre ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37599</th>\n",
       "      <td>We're going shopping.</td>\n",
       "      <td>Nous allons faire des courses.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            src                             dst\n",
       "914                  Take mine.                 Prenez le mien.\n",
       "8302            I'm so unlucky!            Quelle poisse j'ai !\n",
       "31645      We're closing early.               Nous fermons tôt.\n",
       "52071  Have you read that book?             As-tu lu ce livre ?\n",
       "37599     We're going shopping.  Nous allons faire des courses."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48586</th>\n",
       "      <td>She couldn't afford it.</td>\n",
       "      <td>\\t Elle n'en avait pas les moyens. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>I like his attitude.</td>\n",
       "      <td>\\t J'apprécie son attitude. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6560</th>\n",
       "      <td>Tom went pale.</td>\n",
       "      <td>\\t Tom a pâli. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050</th>\n",
       "      <td>She decided to go.</td>\n",
       "      <td>\\t Elle a décidé d'y aller. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27856</th>\n",
       "      <td>He can play a flute.</td>\n",
       "      <td>\\t Il sait jouer de la flûte. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                    dst\n",
       "48586  She couldn't afford it.  \\t Elle n'en avait pas les moyens. \\n\n",
       "28828     I like his attitude.         \\t J'apprécie son attitude. \\n\n",
       "6560            Tom went pale.                      \\t Tom a pâli. \\n\n",
       "20050       She decided to go.         \\t Elle a décidé d'y aller. \\n\n",
       "27856     He can play a flute.       \\t Il sait jouer de la flûte. \\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dst 열에 <sos>로 \\t, <eos>로 \\n 을 추가\n",
    "lines.dst = lines.dst.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글자 집합 생성 (단어가 아님)\n",
    "src_vocab = set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "dst_vocab = set()\n",
    "for line in lines.dst:\n",
    "    for char in line:\n",
    "        dst_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 106\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "dst_vocab_size = len(dst_vocab)+1\n",
    "print(src_vocab_size, dst_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "dst_vocab = sorted(list(dst_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(dst_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, 'С': 100, '\\u2009': 101, '\\u200b': 102, '‘': 103, '’': 104, '\\u202f': 105}\n"
     ]
    }
   ],
   "source": [
    "# 각 글자에 인덱스 부여\n",
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "dst_to_index = dict([(word, i+1) for i, word in enumerate(dst_vocab)])\n",
    "print(src_to_index)\n",
    "print(dst_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [31, 58, 10], [31, 58, 10], [41, 70, 63, 2], [41, 70, 63, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 영어 데이터에 대한 정수 인코딩\n",
    "encoder_input = []\n",
    "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
    "      temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2], [1, 3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [1, 3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 프랑스어 데이터에 대한 정수 인코딩\n",
    "decoder_input = []\n",
    "for line in lines.dst:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      temp_X.append(dst_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 48, 53, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2], [3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 예측값과 비교하기 위한 실제값\n",
    "# 정수 인코딩 과정에서 <sos>를 제거\n",
    "decoder_target = []\n",
    "for line in lines.dst:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      if t>0:\n",
    "        temp_X.append(dst_to_index[w])\n",
    "      t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 76\n"
     ]
    }
   ],
   "source": [
    "# 패딩을 위해서 영어 문장과 프랑스어 문장 각각에 대해서 가장 길이가 긴 샘플의 길이 확인\n",
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_dst_len = max([len(line) for line in lines.dst])\n",
    "print(max_src_len, max_dst_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 문장의 평균 길이 : 19.4515\n",
      "불어 문장의 평균 길이 : 28.501116666666668\n"
     ]
    }
   ],
   "source": [
    "# 평균 샘플 길이\n",
    "print('영어 문장의 평균 길이 : {}'.format(sum(map(len, lines.src))/len(lines.src)))\n",
    "print('불어 문장의 평균 길이 : {}'.format(sum(map(len, lines.dst))/len(lines.dst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩시 사용할 크기 결정\n",
    "pad_src_len = 25\n",
    "pad_dst_len = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=pad_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=pad_dst_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=pad_dst_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 교사 강요(Teacher forcing)\n",
    "- 훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고,\n",
    "- 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용\n",
    "- RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법을 교사 강요라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. seq2seq 기계 번역기 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size), name='Encoder_Input')\n",
    "encoder_lstm = LSTM(units=256, return_state=True, name='Encoder_LSTM')\n",
    "# 인코더의 내부 상태를 디코더로 넘겨주어야 하기 때문에 return_state=True로 설정\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태.\n",
    "# 이겻이 컨텍스트 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, dst_vocab_size), name='Decoder_Input')\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 79)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 106)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 344064      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  371712      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 106)    27242       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 743,018\n",
      "Trainable params: 743,018\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_softmax_layer = Dense(dst_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, 'image/seq2seq.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "modelpath = \"model/seq2seq-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.7609\n",
      "Epoch 00001: val_loss improved from inf to 0.69108, saving model to model/seq2seq-01-0.6911.hdf5\n",
      "48000/48000 [==============================] - 96s 2ms/sample - loss: 0.7606 - val_loss: 0.6911\n",
      "Epoch 2/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4789\n",
      "Epoch 00002: val_loss improved from 0.69108 to 0.56103, saving model to model/seq2seq-02-0.5610.hdf5\n",
      "48000/48000 [==============================] - 107s 2ms/sample - loss: 0.4788 - val_loss: 0.5610\n",
      "Epoch 3/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4028\n",
      "Epoch 00003: val_loss improved from 0.56103 to 0.50355, saving model to model/seq2seq-03-0.5036.hdf5\n",
      "48000/48000 [==============================] - 97s 2ms/sample - loss: 0.4028 - val_loss: 0.5036\n",
      "Epoch 4/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.3586\n",
      "Epoch 00004: val_loss improved from 0.50355 to 0.45609, saving model to model/seq2seq-04-0.4561.hdf5\n",
      "48000/48000 [==============================] - 97s 2ms/sample - loss: 0.3586 - val_loss: 0.4561\n",
      "Epoch 5/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.3288\n",
      "Epoch 00005: val_loss improved from 0.45609 to 0.43013, saving model to model/seq2seq-05-0.4301.hdf5\n",
      "48000/48000 [==============================] - 87s 2ms/sample - loss: 0.3288 - val_loss: 0.4301\n",
      "Epoch 6/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.3067\n",
      "Epoch 00006: val_loss improved from 0.43013 to 0.41273, saving model to model/seq2seq-06-0.4127.hdf5\n",
      "48000/48000 [==============================] - 93s 2ms/sample - loss: 0.3067 - val_loss: 0.4127\n",
      "Epoch 7/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2894- ETA: 0s - loss: 0\n",
      "Epoch 00007: val_loss improved from 0.41273 to 0.39853, saving model to model/seq2seq-07-0.3985.hdf5\n",
      "48000/48000 [==============================] - 86s 2ms/sample - loss: 0.2894 - val_loss: 0.3985\n",
      "Epoch 8/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2753\n",
      "Epoch 00008: val_loss improved from 0.39853 to 0.38907, saving model to model/seq2seq-08-0.3891.hdf5\n",
      "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2753 - val_loss: 0.3891\n",
      "Epoch 9/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2636\n",
      "Epoch 00009: val_loss improved from 0.38907 to 0.38363, saving model to model/seq2seq-09-0.3836.hdf5\n",
      "48000/48000 [==============================] - 87s 2ms/sample - loss: 0.2636 - val_loss: 0.3836\n",
      "Epoch 10/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2536\n",
      "Epoch 00010: val_loss improved from 0.38363 to 0.37683, saving model to model/seq2seq-10-0.3768.hdf5\n",
      "48000/48000 [==============================] - 79s 2ms/sample - loss: 0.2535 - val_loss: 0.3768\n",
      "Epoch 11/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "Epoch 00011: val_loss improved from 0.37683 to 0.37302, saving model to model/seq2seq-11-0.3730.hdf5\n",
      "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2449 - val_loss: 0.3730\n",
      "Epoch 12/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2371\n",
      "Epoch 00012: val_loss improved from 0.37302 to 0.37184, saving model to model/seq2seq-12-0.3718.hdf5\n",
      "48000/48000 [==============================] - 93s 2ms/sample - loss: 0.2370 - val_loss: 0.3718\n",
      "Epoch 13/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2301\n",
      "Epoch 00013: val_loss improved from 0.37184 to 0.36751, saving model to model/seq2seq-13-0.3675.hdf5\n",
      "48000/48000 [==============================] - 88s 2ms/sample - loss: 0.2301 - val_loss: 0.3675\n",
      "Epoch 14/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2235- ETA: 0s - loss: 0\n",
      "Epoch 00014: val_loss improved from 0.36751 to 0.36669, saving model to model/seq2seq-14-0.3667.hdf5\n",
      "48000/48000 [==============================] - 88s 2ms/sample - loss: 0.2235 - val_loss: 0.3667\n",
      "Epoch 15/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2176\n",
      "Epoch 00015: val_loss improved from 0.36669 to 0.36476, saving model to model/seq2seq-15-0.3648.hdf5\n",
      "48000/48000 [==============================] - 84s 2ms/sample - loss: 0.2176 - val_loss: 0.3648\n",
      "Epoch 16/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2121\n",
      "Epoch 00016: val_loss improved from 0.36476 to 0.36470, saving model to model/seq2seq-16-0.3647.hdf5\n",
      "48000/48000 [==============================] - 85s 2ms/sample - loss: 0.2121 - val_loss: 0.3647\n",
      "Epoch 17/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2071\n",
      "Epoch 00017: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 90s 2ms/sample - loss: 0.2071 - val_loss: 0.3662\n",
      "Epoch 18/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.2023\n",
      "Epoch 00018: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 84s 2ms/sample - loss: 0.2023 - val_loss: 0.3661\n",
      "Epoch 19/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1980\n",
      "Epoch 00019: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 78s 2ms/sample - loss: 0.1980 - val_loss: 0.3669\n",
      "Epoch 20/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1939\n",
      "Epoch 00020: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 78s 2ms/sample - loss: 0.1939 - val_loss: 0.3690\n",
      "Epoch 21/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1899\n",
      "Epoch 00021: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 85s 2ms/sample - loss: 0.1899 - val_loss: 0.3709\n",
      "Epoch 22/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1861\n",
      "Epoch 00022: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 84s 2ms/sample - loss: 0.1862 - val_loss: 0.3720\n",
      "Epoch 23/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1827\n",
      "Epoch 00023: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 81s 2ms/sample - loss: 0.1827 - val_loss: 0.3718\n",
      "Epoch 24/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1794\n",
      "Epoch 00024: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 91s 2ms/sample - loss: 0.1793 - val_loss: 0.3746\n",
      "Epoch 25/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1762\n",
      "Epoch 00025: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 78s 2ms/sample - loss: 0.1762 - val_loss: 0.3749\n",
      "Epoch 26/50\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1730\n",
      "Epoch 00026: val_loss did not improve from 0.36470\n",
      "48000/48000 [==============================] - 87s 2ms/sample - loss: 0.1730 - val_loss: 0.3794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247cf820488>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target,\n",
    "          batch_size=64, epochs=50, validation_split=0.2,\n",
    "          callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
